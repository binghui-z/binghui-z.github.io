
<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


  <title>Binghui Zuo</title>
  
  <meta name="author" content="Binghui Zuo">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="image/head.jpg" type="image/x-icon" />
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ˜Ž</text></svg>"> -->
</head> 
<style>
  td {
    border-bottom: 1px dashed gray; 
  }
  td.no-border {
    border-bottom: none;
  }

</style>
<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td class="no-border"; style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td class="no-border"; style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Binghui Zuo | å·¦ç‚³è¾‰</name>
              </p>
              <p>I'm a Ph.D. student at <a href="https://www.seu.edu.cn/"> Southeast University</a>. Starting from 2021, I have studied in Vision and Cognition Lab (VCL), advised by <a href="https://www.yangangwang.com/"> Prof. Yangang Wang</a>. Prior to that, I got my B.E. degree (Top 1% graduates) of automation at <a href="http://www.qut.edu.cn/"> Qingdao University of Technology</a> in 2021, supervised by <a href="https://ice.qut.edu.cn/info/1210/7986.htm"> Prof. Zhao</a>.
              </p>
              </p>
              I'm interested in 3D computer vision and computer graphics. Much of my research is about reconstructing single hand, interacting hands or hand-object from images. Currently, I am attempting to generate personalized human avatars from monocular images with diffusion models. 
              </p>
              <!-- </p> -->
              <!-- Served as the paper reviewer of CVPR / ICCV / NeurIPS and etc. -->
              <!-- </p> -->

              <!-- </p>
              <span style="color:red">Now, I am actively applying for Ph.D position in 2024 fall.</span>
              </p> -->
              <p style="text-align:center">
                <a href="mailto:binghuizuo@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=zh-CN&user=YajLTJMAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/z_binghui">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/binghui-z">Github</a> <!--&nbsp/&nbsp
                <a href="docs/resume.pdf"> ResumÃ© (PDF) </a>-->
              </p>
            </td>
            <td class="no-border"; style="padding:2.5%;width:40%;max-width:40%">
              <a href="#"><img style="width:100%;max-width:100%" alt="profile photo" src="image/myself.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <!-- News -->
        <table
          style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <td class="no-border"; style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <hr class="styled-hr" style="width:100%;"></hr>
          </td>
        </table>

        <ul>
          <li>
            <span style="color: gray" size="6px">[2024.09]</span> &#127881&#127881&#127881 One paper accepted by <strong>TVCG</strong>!!! My first top journal as the first author!
          </li>
          <li>
            <span style="color: gray" size="6px">[2024.02]</span> One paper accepted by <strong>SPL</strong>.
          </li>
          <li>
            <span style="color: gray" size="6px">[2023.07]</span> Two papers accepted by <strong>ICCV2023</strong>!!! My first top conference as the first author!
          </li>
          <li>
            <span style="color: gray" size="6px">[2023.03]</span> One paper accepted by <strong>CVPR2023</strong>.
          </li>
          <li>
            <span style="color: gray" size="6px">[2023.01]</span> One paper accepted by TVCG2023, and another accepted by GM2023. 
          </li>
          <li>
            <span style="color: gray" size="6px">[2022.03]</span> One paper accepted by CVPR 2022. 
          </li>
          <li>
            <span style="color: gray" size="6px">[2021.12]</span> Create this <a href="https://binghui-z.github.io/"> Homepage.</a>
          </li>
        </ul> 
      
        <!--%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <td class="no-border"; style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <hr class="styled-hr" style="width:100%;"></hr>
            </td>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <!-- ======================================================================================================= -->
          <!-- ECCV1æŠ•ç¨¿ -->
          <tr onmouseout="GraspDiff_stop()" onmouseover="GraspDiff_start()">
            <td class="no-border"; style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='GraspDiff_image'>
                  <img src='image/GraspDiff_0.png' width="160"></div>
                <img src='image/GraspDiff_1.png' width="160">
              </div>
              <script type="text/javascript">
                function GraspDiff_start() {
                  document.getElementById('GraspDiff_image').style.opacity = "1";
                }

                function GraspDiff_stop() {
                  document.getElementById('GraspDiff_image').style.opacity = "0";
                }
                GraspDiff_stop()
              </script>
            </td>
            <td class="no-border"; style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>GraspDiff: Grasping Generation for Hand-Object Interaction With Multimodal Guided Diffusion</papertitle>
              <br>
              <strong>Binghui Zuo</strong>,
              Zimeng Zhao, 
              Wenqian Sun,
              Xiaohan Yuan,
              Zhipeng Yu,
              Yangang Wang
              <br>
              <em>IEEE Transactions on Visualization and Computer Graphics (TVCG)</em>, 2024
              <br>
              <a href="https://binghui-z.github.io/">Paper</a>
              <p></p>
              <p></p>
            </td>
          </tr>

          <!-- ECCV2æŠ•ç¨¿ -->
          <!-- <tr onmouseout="SynInter_stop()" onmouseover="SynInter_start()">
            <td class="no-border"; style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='SynInter_image'>
                  <img src='image/SynInter_0.png' width="160"></div>
                <img src='image/SynInter_1.png' width="160">
              </div>
              <script type="text/javascript">
                function SynInter_start() {
                  document.getElementById('SynInter_image').style.opacity = "1";
                }

                function SynInter_stop() {
                  document.getElementById('SynInter_image').style.opacity = "0";
                }
                SynInter_stop()
              </script>
            </td>
            <td class="no-border"; style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Synthesizing Interaction of Two Hands and Articulated Objects from a Single Target State with Two-stage Diffusion</papertitle>
              <br>
              Wenqian Sun,
              <strong>Binghui Zuo</strong>,
              Zimeng Zhao, 
              Zijing Wu,
              Yangang Wang
              <br>
              <em>Preprint
              <br>
              <p></p>
              <p>
                This paper focuses on a new task of synthesizing interaction between two hands and an articulated object from a single target state and presents an effective approach to achieve this task.
              </p>
            </td>
          </tr> -->
          
          <!-- ECCV3æŠ•ç¨¿ -->
          <!-- <tr onmouseout="T2C_stop()" onmouseover="T2C_start()">
            <td class="no-border"; style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='T2C_image'>
                  <img src='image/T2C_0.png' width="160"></div>
                <img src='image/T2C_1.png' width="160">
              </div>
              <script type="text/javascript">
                function T2C_start() {
                  document.getElementById('T2C_image').style.opacity = "1";
                }

                function T2C_stop() {
                  document.getElementById('T2C_image').style.opacity = "0";
                }
                T2C_stop()
              </script>
            </td>
            <td class="no-border"; style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>T2C: Text-guided 4D Cloth Generation</papertitle>
              <br>
              Zhipeng Yu,
              Zimeng Zhao, 
              Yanxi Du,
              Yuzhou Zheng,
              <strong>Binghui Zuo</strong>,
              Yangang Wang
              <br>
              <em>Preprint
              <br>
              <p></p>
              <p>
                This paper introduces a novel approach named T2C, which employs a multilayered clothing representation and a physics-based clothing animation paradigm to generate text-controlled Clothed 4D Humans, expanding the boundaries of the aforementioned issues.
              </p>
            </td>
          </tr> -->

          <!-- TIPæŠ•ç¨¿ -->
          <!-- <tr onmouseout="NPHand_stop()" onmouseover="NPHand_start()">
            <td class="no-border"; style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='NPHand_image'>
                  <img src='image/NPHand_0.jpg' width="160"></div>
                <img src='image/NPHand_0.jpg' width="160">
              </div>
              <script type="text/javascript">
                function NPHand_start() {
                  document.getElementById('NPHand_image').style.opacity = "1";
                }

                function NPHand_stop() {
                  document.getElementById('NPHand_image').style.opacity = "0";
                }
                NPHand_stop()
              </script>
            </td>
            <td class="no-border"; style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>NP-Hand: Novel Perspective Hand Image Synthesis Guided by Normals</papertitle>
              <br>
              <strong>Binghui Zuo</strong>,
              Wenqian Sun,
              Zimeng Zhao, 
              Xiaohan Yuan,
              Yangang Wang
              <br>
              <em>Preprint
              <br>
              <p></p>
              <p>
              In this paper, we propose NP-Hand, a framework that elegantly combines the diffusion model and generative adversarial network to synthesize hand images from novel perspectives. To maintain the consistency between inputs and synthesis, we creatively introduce normal maps into NP-Hand to guide the whole synthesizing process.
              </p>
            </td>
          </tr> -->
          <!-- ======================================================================================================= -->

          <!-- SPL -->
          <tr onmouseout="MCG_stop()" onmouseover="MCG_start()">
            <td class="no-border"; style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='MCG_image'>
                  <img src='image/music_0.jpg' width="160"></div>
                <img src='image/music_0.jpg' width="160">
              </div>
              <script type="text/javascript">
                function MCG_start() {
                  document.getElementById('MCG_image').style.opacity = "1";
                }

                function MCG_stop() {
                  document.getElementById('MCG_image').style.opacity = "0";
                }
                MCG_stop()
              </script>
            </td>
            <td class="no-border"; style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Music Conditioned Generation for Human-centric Video</papertitle>
              <br>
              Zimeng Zhao,
              <strong>Binghui Zuo</strong>,
              Yangang Wang
              <br>
              <em>IEEE Signal Processing Letters (SPL)</em>, 2024
              <br>
              <a href="https://ieeexplore.ieee.org/document/10415104">Paper</a>
              <p></p>
              <p>
              Our key idea is to build a temporal generation framework dominated by DDPM and assisted by VAE and GAN. To produce videos with both long duration and high quality, our framework first generates small-scale keyframes and then generates high-resolution videos.
              </p>
            </td>
          </tr>

          <!-- ICCV2023 -->
          <tr onmouseout="interprior_stop()" onmouseover="interprior_start()">
            <td class="no-border"; style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='interprior_image'>
                  <img src='image/interprior_1.png' width="160"></div>
                <img src='image/interprior_0.png' width="160">
              </div>
              <script type="text/javascript">
                function interprior_start() {
                  document.getElementById('interprior_image').style.opacity = "1";
                }

                function interprior_stop() {
                  document.getElementById('interprior_image').style.opacity = "0";
                }
                interprior_stop()
              </script>
            </td>
            <td class="no-border"; style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Reconstructing Interacting Hands with Interaction Prior from Monocular Images</papertitle>
              <br>
              <strong>Binghui Zuo</strong>,
              Zimeng Zhao, 
              Wenqian Sun,
              Wei Xie, 
              Zhou Xue,
              Yangang Wang
              <br>
              <em>IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2308.14082/">Paper</a>
              /
              <a href="https://www.yangangwang.com/papers/iccv2023_interprior/BinghuiZuo-ICCV2023_InterPrior.html">Project</a>
              /
              <a href="https://github.com/binghui-z/InterPrior_pytorch">Code [comming soon]</a>
              <p></p>
              <p>
              The key idea is first to construct a two-hand interaction prior and recast the interaction reconstruction task as the conditional sampling from the prior.
              </p>
            </td>
          </tr>
        
          <!-- ICCV2023 -->
          <tr onmouseout="Nonrigid_stop()" onmouseover="Nonrigid_start()">
            <td class="no-border"; style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nonrigid_image'>
                  <img src='image/Nonrigid_0.png' width="160"></div>
                <img src='image/Nonrigid_1.png' width="160">
              </div>
              <script type="text/javascript">
                function Nonrigid_start() {
                  document.getElementById('nonrigid_image').style.opacity = "1";
                }

                function Nonrigid_stop() {
                  document.getElementById('nonrigid_image').style.opacity = "0";
                }
                Nonrigid_stop()
              </script>
            </td>
            <td class="no-border"; style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Nonrigid Object Contact Estimation With Regional Unwrapping Transformer</papertitle>
              <br>
              Wei Xie, 
              Zimeng Zhao, 
              Shiying Li,
              <strong>Binghui Zuo</strong>,
              Yangang Wang
              <br>
              <em>IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2308.14074">Paper</a>
              /
              <a href="https://www.yangangwang.com/papers/iccv2023-nonrigid/XIE-NONRIGID-2023-07-paper.html">Project</a>
              <p></p>
              <p>
              A novel hand-object contact representation called RUPs (Region Unwrapping Profiles) is proposed, which unwrap the roughly estimated hand-object surfaces as multiple high-resolution 2D regional profiles.
              </p>
            </td>
          </tr>

          <!-- CVPR2023 -->
          <tr onmouseout="markerless_stop()" onmouseover="markerless_start()">
            <td class="no-border"; style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='markerless_image'><video  width=100% height=100% muted autoplay loop>
                <source src="image/markerless.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='image/markerless.png' width=150>
              </div>
              <script type="text/javascript">
                function markerless_start() {
                  document.getElementById('markerless_image').style.opacity = "1";
                }

                function markerless_stop() {
                  document.getElementById('markerless_image').style.opacity = "0";
                }
                markerless_stop()
              </script>
            </td>
            <td class="no-border"; style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Semi-supervised Hand Appearance Recovery via Structure Disentanglement and Dual Adversarial Discrimination</papertitle>
              <br> 
              Zimeng Zhao, 
              <strong>Binghui Zuo</strong>,
              Zhiyu Long,
              Yangang Wang
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2303.06380">Paper</a>
              /
              <a href="https://www.yangangwang.com/papers/CVPR2023/ZHAO-SHAR-2023-03.html">Project</a>
              <p>
              A solution is proposed to recover clear hand appearance from degraded images. In a semi-supervised learning manner, we first disentangle the bare hand structure from those degraded images and then wrap the appearance to this structure with a dual adversarial discrimination (DAD) scheme.
              </p>
            </td>
          </tr>

          <!-- TVCG -->
          <tr onmouseout="Skeleton_stop()" onmouseover="Skeleton_start()">
            <td class="no-border"; style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='skeleton_image'>
                  <img src='image/skeleton_1.png' width="160"></div>
                <img src='image/skeleton0.png' width="160">
              </div>
              <script type="text/javascript">
                function Skeleton_start() {
                  document.getElementById('skeleton_image').style.opacity = "1";
                }

                function Skeleton_stop() {
                  document.getElementById('skeleton_image').style.opacity = "0";
                }
                Skeleton_stop()
              </script>
            </td>
            <td class="no-border"; style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Skeleton Extraction for Articulated Objects with the Spherical Unwrapping Profiles</papertitle>
              <br>
              Zimeng Zhao, 
              Wei Xie, 
              <strong>Binghui Zuo</strong>,
              Yangang Wang
              <br>
              <em>IEEE Transactions on Visualization and Computer Graphics (TVCG)</em>, 2023
              <br>
              <a href="https://www.yangangwang.com/papers/TVCG2023/ZHAO-SUPPLE-TVCG-2023.pdf">Paper</a>
              /
              <a href="https://www.yangangwang.com/papers/TVCG2023/ZHAO-SUPPLE-TVCG-2023.html">Project</a>
              <p></p>
              <p>
              A novel unwrapping method named Spherical Unwrapping Profiles is proposed, which maps a surface into image planes independent of mesh topologies.
              </p>
            </td>
          </tr>

          <!-- CVPR2022 -->
          <tr onmouseout="stable_stop()" onmouseover="stable_start()">
            <td class="no-border"; style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='stable_image'><video  width=100% height=100% muted autoplay loop>
                <source src="image/stable_video.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='image/stable.png' width=160>
              </div>
              <script type="text/javascript">
                function stable_start() {
                  document.getElementById('stable_image').style.opacity = "1";
                }

                function stable_stop() {
                  document.getElementById('stable_image').style.opacity = "0";
                }
                stable_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Stability-driven Contact Reconstruction From Monocular Color Images</papertitle>
              <br>
              Zimeng Zhao, 
              <strong>Binghui Zuo</strong>,
              Wei Xie, 
              Yangang Wang
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Stability-Driven_Contact_Reconstruction_From_Monocular_Color_Images_CVPR_2022_paper.pdf">Paper</a>
              /
              <a href="https://www.yangangwang.com/papers/ZZM-SCR-2022-03.html">Project</a>
              <p>
              We use physical engine to optimize reconstructed hand-object interaction, thus produce more realistic result.
              </p>
            </td>
          </tr>
          
          <!-- CVM -->
          <tr onmouseout="hdo_stop()" onmouseover="hdo_start()">
            <td class="no-border"; style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hdo_image'><video  width=100% height=100% muted autoplay loop>
                <source src="image/hdo.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='image/hdo.png' width=130>
              </div>
              <script type="text/javascript">
                function hdo_start() {
                  document.getElementById('hdo_image').style.opacity = "1";
                }

                function hdo_stop() {
                  document.getElementById('hdo_image').style.opacity = "0";
                }
                hdo_stop()
              </script>
            </td>
            <td class="no-border"; style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>HMDO : Markerless Multi-view Hand Manipulation Capture with Deformable Objects</papertitle>
              <br>
              Wei Xie*, 
              Zhipeng Yu*, 
              Zimeng Zhao,
              <strong>Binghui Zuo</strong>,
              Yangang Wang
              <br>
              <!-- <em>CVPR</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
              <em>International Conference on Computational Visual Media (CVM)</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2301.07652.pdf">Paper</a>
              /
              <a href="https://www.yangangwang.com/papers/cvm2023-hmdo/XIE-HMDO-2023.html">Project</a>
              <p>
              We construct the first markerless deformable interaction dataset recording interactive motions of the hands and deformable object. Besides that, a baseline for hand manipulating with deformable objects is proposed.
              </p>
            </td>
          </tr>

          <!-- ICIG -->
          <tr onmouseout="IRiHR_stop()" onmouseover="IRiHR_start()">
            <td class="no-border"; style="padding:10px;width:15%;vertical-align:middle">
              <div class="one">
                <div class="two" id='implicit_image'>
                  <img src='image/IRiHR_1.png' width="170"></div>
                <img src='image/IRiHR_0.png' width="170">
              </div>
              <script type="text/javascript">
                function IRiHR_start() {
                  document.getElementById('implicit_image').style.opacity = "1";
                }

                function IRiHR_stop() {
                  document.getElementById('implicit_image').style.opacity = "0";
                }
                IRiHR_stop()
              </script>
            </td>
            <td class="no-border"; style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Implicit Representation for Interacting Hands Reconstruction from Monocular Color Images</papertitle>
              <br>
              <strong>Binghui Zuo</strong>,
              Zimeng Zhao, 
              Wei Xie, 
              Yangang Wang
              <br>
              <em>International Conference on Image and Graphics (ICIG, Oral)</em>, 2023
              <br>
              <a href="https://link.springer.com/chapter/10.1007/978-3-031-46305-1_2">Paper</a>
              <p></p>
              <p>
              A novel framework for representing the surface of interacting hands with implicit functions is proposed, which implicitly reconstructs interacting hands with image features as query strategy and condition.
              </p>
            </td>
          </tr>

        <!--%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <td class="no-border"; style="padding:20px;width:100%;vertical-align:middle">
              <heading>Experiences</heading>
              <hr class="styled-hr" style="width:100%;"></hr>
            </td>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <!-- bytedance -->
          <tr onmouseout="neuralsimulator_stop()" onmouseover="neuralsimulator_start()"></tr>
            <td class="no-border"; style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="three" id='bytedance'></div>
                <img src='image/bytedance1.png' width="180">
              </div>
            </td>
            <td class="no-border"; style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Research Intern, Bytedance</papertitle>
                <p>Feb. 2023 - Apr. 2023</p>
            </td>
          <tr>

        <!-- Honors -->
        <table
          style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <td class="no-border"; style="padding:20px;width:100%;vertical-align:middle">
            <heading>Honors & Awards</heading>
            <hr class="styled-hr" style="width:100%;"></hr>
          </td>
        </table>
          <ul>
            <li style="padding-bottom:0.5em">
              <span style="display:inline-block;width:6em">2023.04</span>
              <span>Huawei Scholarship. </span>
            </li>
            <li style="padding-bottom:0.5em">
              <span style="display:inline-block;width:6em">2022.09</span>
              <span> Second-class Scholarship in Southeast University. </span>
            </li>
            <li style="padding-bottom:0.5em">
              <span style="display:inline-block;width:6em">2021.06</span>
              <span> Excellent Graduate of Shandong Province. </span>
            </li>
            <li style="padding-bottom:0.5em">
                <span style="display:inline-block;width:6em">2020.05</span>
                <span>Outstanding college students in Shandong Province. </span>
            </li>
            <li style="padding-bottom:0.5em">
                <span style="display:inline-block;width:6em">2019.10</span>
                <span>National Scholarship. </span>
            </li>
          </ul>

        <!--%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td class="no-border"; style="padding:0px">
            <br>
            <p style="text-align:right;font-size:small;">
              Page inspired by <a href="https://jonbarron.info/">Barron</a>.
            </p>
          </td>
        </tbody></table>
    </tr>
  </table>
</body>
</html>
